{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11941191,"sourceType":"datasetVersion","datasetId":7506954},{"sourceId":11941966,"sourceType":"datasetVersion","datasetId":7507376},{"sourceId":468799,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":378201,"modelId":398467}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nimport pandas as pd\nfrom datetime import datetime\nimport os\n\n# Configuration\nvideo_source = \"/kaggle/input/videos/Video/vid3.mp4\"\ncsv_file = 'person_detections.csv'\ncustom_object = {'mae': tf.keras.losses.MeanAbsoluteError()}\nMAX_AGE = 116.0  # Maximum age in UTK face dataset\ngender_dict = {0: \"Male\", 1: \"Female\"}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T08:10:02.619785Z","iopub.execute_input":"2025-07-12T08:10:02.620149Z","iopub.status.idle":"2025-07-12T08:10:02.626424Z","shell.execute_reply.started":"2025-07-12T08:10:02.620119Z","shell.execute_reply":"2025-07-12T08:10:02.625677Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"try:\n    print(\"Loading models.\")\n    face_detector = load_model('/kaggle/input/model-task2/keras/default/1/facedetectortask2.h5',\n                              custom_objects=custom_object)\n    age_model = load_model('/kaggle/input/model-task2/keras/default/1/agetask2.h5',\n                           custom_objects=custom_object)\n    gender_model = load_model('/kaggle/input/model-task2/keras/default/1/gendertask2.h5')\n    print(\"Models loaded successfully.\")\nexcept Exception as e:\n    print(f\"Error loading models: {e}\")\n    exit(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T08:10:04.353010Z","iopub.execute_input":"2025-07-12T08:10:04.353278Z","iopub.status.idle":"2025-07-12T08:10:05.209585Z","shell.execute_reply.started":"2025-07-12T08:10:04.353258Z","shell.execute_reply":"2025-07-12T08:10:05.208976Z"}},"outputs":[{"name":"stdout","text":"Loading models.\nModels loaded successfully.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"def preprocess_image(img, size=(128, 128)):\n    if not isinstance(img, np.ndarray) or img.size == 0 or len(img.shape) < 2:\n        raise ValueError(f\"Invalid input image: shape {img.shape if isinstance(img, np.ndarray) else 'None'}\")\n    \n    if len(img.shape) == 2 or (len(img.shape) == 3 and img.shape[2] == 1):\n        if len(img.shape) == 3:\n            img = img[:, :, 0]\n    else:\n        try:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        except Exception as e:\n            raise ValueError(f\"Failed to convert to grayscale: {e}. Shape: {img.shape}\")\n    \n    # Resizing, normalizing, and adding dimensions\n    img = cv2.resize(img, size, interpolation=cv2.INTER_LANCZOS4)\n    img = img.astype(np.float32) / 255.0\n    img = np.expand_dims(img, axis=-1)  # Shape: (128, 128, 1)\n    img = np.expand_dims(img, axis=0)   # Shape: (1, 128, 128, 1)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T08:10:07.489318Z","iopub.execute_input":"2025-07-12T08:10:07.489599Z","iopub.status.idle":"2025-07-12T08:10:07.495707Z","shell.execute_reply.started":"2025-07-12T08:10:07.489579Z","shell.execute_reply":"2025-07-12T08:10:07.494955Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def detect_faces(frame, min_confidence=0.7, window_size=(128, 128), stride=32):\n    if not isinstance(frame, np.ndarray) or frame.size == 0 or len(frame.shape) != 3 or frame.shape[2] != 3:\n        print(f\"Invalid frame: expected 3-channel BGR image, got shape {frame.shape if isinstance(frame, np.ndarray) else 'None'}\")\n        return []\n    \n    frame = cv2.resize(frame, (640, 480))\n    height, width = frame.shape[:2]\n    confirmed_faces = []\n    \n    for y in range(0, height - window_size[1] + 1, stride):\n        for x in range(0, width - window_size[0] + 1, stride):\n            window = frame[y:y+window_size[1], x:x+window_size[0]]\n            if window.size == 0 or window.shape[0] != window_size[1] or window.shape[1] != window_size[0] or window.shape[2] != 3:\n                print(f\"Invalid window at ({x}, {y}): shape {window.shape}\")\n                continue\n            try:\n                face_input = preprocess_image(window)\n                if face_input.shape != (1, 128, 128, 1):\n                    print(f\"Invalid face_input shape at ({x}, {y}): got {face_input.shape}\")\n                    continue\n                confidence = face_detector.predict(face_input, verbose=0)[0][0]\n                if confidence > min_confidence:\n                    confirmed_faces.append((x, y, window_size[0], window_size[1]))\n            except Exception as e:\n                print(f\"Error processing window at ({x}, {y}): {e}. Window shape: {window.shape}\")\n                continue\n    \n    return confirmed_faces","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T08:10:11.049491Z","iopub.execute_input":"2025-07-12T08:10:11.050289Z","iopub.status.idle":"2025-07-12T08:10:11.057961Z","shell.execute_reply.started":"2025-07-12T08:10:11.050261Z","shell.execute_reply":"2025-07-12T08:10:11.057090Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def predict_age_gender(face_img):\n    try:\n        input_img = preprocess_image(face_img)\n        gender_pred = gender_model.predict(input_img, verbose=0)[0][0]\n        age_pred = age_model.predict(input_img, verbose=0)[0][0]\n        gender = 1 if gender_pred > 0.5 else 0\n        age = float(age_pred) * MAX_AGE\n        return gender, age\n    except Exception as e:\n        print(f\"Error in age/gender prediction: {e}. Input shape: {face_img.shape}\")\n        raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T08:10:14.392436Z","iopub.execute_input":"2025-07-12T08:10:14.393224Z","iopub.status.idle":"2025-07-12T08:10:14.397929Z","shell.execute_reply.started":"2025-07-12T08:10:14.393197Z","shell.execute_reply":"2025-07-12T08:10:14.397115Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def process_frame(frame, min_confidence=0.7):\n    if not isinstance(frame, np.ndarray) or frame.size == 0 or len(frame.shape) != 3 or frame.shape[2] != 3:\n        raise ValueError(f\"Invalid frame: expected 3-channel BGR image, got shape {frame.shape if isinstance(frame, np.ndarray) else 'None'}\")\n    \n    frame = cv2.resize(frame, (640, 480))\n    faces = detect_faces(frame, min_confidence)\n    detections = []\n    for (x, y, w, h) in faces:\n        face_img = frame[y:y+h, x:x+w]\n        if face_img.size == 0 or face_img.shape[0] == 0 or face_img.shape[1] == 0:\n            print(f\"Invalid face image at ({x}, {y}, {w}, {h}): shape {face_img.shape}\")\n            continue\n        gender, age = predict_age_gender(face_img)\n        if(age>60):\n            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n            detections.append({\n                'Timestamp': timestamp,\n                'Age': round(max(0, age)),\n                'Gender': gender_dict[gender]\n            })\n    if detections:\n        pd.DataFrame(detections).to_csv(csv_file, mode='a', header=False, index=False)\n    return frame","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T08:25:14.706857Z","iopub.execute_input":"2025-07-12T08:25:14.707145Z","iopub.status.idle":"2025-07-12T08:25:14.713905Z","shell.execute_reply.started":"2025-07-12T08:25:14.707125Z","shell.execute_reply":"2025-07-12T08:25:14.713165Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"try:\n    if not os.path.exists(csv_file):\n        pd.DataFrame(columns=['Timestamp', 'Age', 'Gender']).to_csv(csv_file, index=False)\n    \n    cap = cv2.VideoCapture(video_source)\n    if not cap.isOpened():\n        print(f\"Error: Could not open video file {video_source}\")\n        exit(1)\n    print(\"Starting video pre-processing\")\n    frame_count = 0\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            print(\"End of video or error reading frame.\")\n            break\n        try:\n            if frame_count % 10 == 0:\n                frame = process_frame(frame)\n            frame_count += 1\n            if frame_count % 100 == 0:\n                print(f\"Processed {frame_count} frames\")\n        except Exception as e:\n            print(f\"Error processing frame {frame_count}: {e}\")\n            continue\n    \n    print(f\"Processed {frame_count} frames. CSV output saved to {csv_file}\")\n    cap.release()\nexcept Exception as e:\n    print(f\"Error in main loop: {e}\")\nfinally:\n    if 'cap' in locals():\n        cap.release()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T08:19:22.067016Z","iopub.execute_input":"2025-07-12T08:19:22.067278Z","iopub.status.idle":"2025-07-12T08:24:44.297463Z","shell.execute_reply.started":"2025-07-12T08:19:22.067258Z","shell.execute_reply":"2025-07-12T08:24:44.296616Z"}},"outputs":[{"name":"stdout","text":"Starting video pre-processing\nProcessed 100 frames\nProcessed 200 frames\nEnd of video or error reading frame.\nProcessed 202 frames. CSV output saved to person_detections.csv\n","output_type":"stream"}],"execution_count":28}]}